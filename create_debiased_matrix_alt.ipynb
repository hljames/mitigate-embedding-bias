{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a \"debiased matrix\" (on the axis of gender) in which the shapes of male and female distributions are the same (excluding appropriately gendered words) which represents the conditional probability of each word pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "import math\n",
    "import numpy as np\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import gensim.downloader as api\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import ot\n",
    "# necessary for 3d plot even if not used\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "from matplotlib.collections import PolyCollection\n",
    "import json\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-29 20:42:02,773 : INFO : loading Word2Vec object from english-wikipedia-articles-20170820-models/enwiki_2017_08_20_fasttext.model\n",
      "2019-07-29 20:42:11,069 : INFO : loading wv recursively from english-wikipedia-articles-20170820-models/enwiki_2017_08_20_fasttext.model.wv.* with mmap=None\n",
      "2019-07-29 20:42:11,074 : INFO : loading vectors from english-wikipedia-articles-20170820-models/enwiki_2017_08_20_fasttext.model.wv.vectors.npy with mmap=None\n",
      "2019-07-29 20:42:11,213 : INFO : loading vectors_vocab from english-wikipedia-articles-20170820-models/enwiki_2017_08_20_fasttext.model.wv.vectors_vocab.npy with mmap=None\n",
      "2019-07-29 20:42:11,337 : INFO : loading vectors_ngrams from english-wikipedia-articles-20170820-models/enwiki_2017_08_20_fasttext.model.wv.vectors_ngrams.npy with mmap=None\n",
      "2019-07-29 20:42:11,751 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-07-29 20:42:11,753 : INFO : setting ignored attribute vectors_vocab_norm to None\n",
      "2019-07-29 20:42:11,763 : INFO : setting ignored attribute vectors_ngrams_norm to None\n",
      "2019-07-29 20:42:11,769 : INFO : setting ignored attribute buckets_word to None\n",
      "2019-07-29 20:42:11,774 : INFO : loading vocabulary recursively from english-wikipedia-articles-20170820-models/enwiki_2017_08_20_fasttext.model.vocabulary.* with mmap=None\n",
      "2019-07-29 20:42:11,777 : INFO : loading trainables recursively from english-wikipedia-articles-20170820-models/enwiki_2017_08_20_fasttext.model.trainables.* with mmap=None\n",
      "2019-07-29 20:42:11,780 : INFO : loading syn1neg from english-wikipedia-articles-20170820-models/enwiki_2017_08_20_fasttext.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-07-29 20:42:11,966 : INFO : loading vectors_vocab_lockf from english-wikipedia-articles-20170820-models/enwiki_2017_08_20_fasttext.model.trainables.vectors_vocab_lockf.npy with mmap=None\n",
      "2019-07-29 20:42:12,137 : INFO : loading vectors_ngrams_lockf from english-wikipedia-articles-20170820-models/enwiki_2017_08_20_fasttext.model.trainables.vectors_ngrams_lockf.npy with mmap=None\n",
      "2019-07-29 20:42:13,279 : INFO : loaded english-wikipedia-articles-20170820-models/enwiki_2017_08_20_fasttext.model\n"
     ]
    }
   ],
   "source": [
    "wiki_model = Word2Vec.load(\"english-wikipedia-articles-20170820-models/enwiki_2017_08_20_fasttext.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 22000\n",
    "k = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per Mikolov's paper \"Distributed Representations of Words and Phrases and their Compositionality,\" we use the following definition of each log conditional probability.\n",
    "\n",
    "$$ \\log P(w_O|w_I) \\approx \\log \\sigma ({v'_{wo}}^T v_{wI}) + \\sum_{i=1}^{k} [\\log {\\sigma ({{-v'_{wi}}^T v_{wI}})}] $$\n",
    "\n",
    "https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the k samples, we similarly follow the methodology in the original paper and construct a unigram distribution raised to the power of (3/4). \n",
    "\n",
    "$$P(w_i) =\\frac{f(w_i)^{3/4}}{\\sum_{j=0}^{n} (f(w_j)^{3/4})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = np.array([wiki_model.wv.vocab[wiki_model.wv.index2word[i]].count for i in range(vocab_size)])\n",
    "word_counts_power = np.power(word_counts,.75)\n",
    "sampling_dist = np.true_divide(word_counts_power,np.sum(word_counts_power))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the probability matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e ** -x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs = np.load('english-wikipedia-articles-20170820-models/enwiki_2017_08_20_fasttext.model.wv.vectors.npy')\n",
    "wvs = wvs[:vocab_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = np.load('english-wikipedia-articles-20170820-models/enwiki_2017_08_20_fasttext.model.trainables.syn1neg.npy')\n",
    "cvs = cvs[:vocab_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_probs = np.load('cond_probs_alt.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: add more gender word pairs (girlfriend, boyfriend, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_word_pairs = [('he','she'),('man','woman'),('his','her'),('himself','herself'), ('him','her'),('men','women'),('husband','wife'),('girl','boy'),('men','women'),('brother','sister'),('mother','father'),('aunt','uncle'),('grandfather','grandmother'),('son','daughter'),('waiter','waitress'),('niece','nephew')]\n",
    "gender_word_pairs_simple = [w for p in gender_word_pairs for w in p] \n",
    "gw_dict = {w:i for (i,w) in enumerate(gender_word_pairs_simple)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aunt': 22,\n",
       " 'boy': 15,\n",
       " 'brother': 18,\n",
       " 'daughter': 27,\n",
       " 'father': 21,\n",
       " 'girl': 14,\n",
       " 'grandfather': 24,\n",
       " 'grandmother': 25,\n",
       " 'he': 0,\n",
       " 'her': 9,\n",
       " 'herself': 7,\n",
       " 'him': 8,\n",
       " 'himself': 6,\n",
       " 'his': 4,\n",
       " 'husband': 12,\n",
       " 'man': 2,\n",
       " 'men': 16,\n",
       " 'mother': 20,\n",
       " 'nephew': 31,\n",
       " 'niece': 30,\n",
       " 'she': 1,\n",
       " 'sister': 19,\n",
       " 'son': 26,\n",
       " 'uncle': 23,\n",
       " 'waiter': 28,\n",
       " 'waitress': 29,\n",
       " 'wife': 13,\n",
       " 'woman': 3,\n",
       " 'women': 17}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure no words have index greater than `vocab_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gw in gender_word_pairs_simple:\n",
    "    j = wiki_model.wv.vocab[gw].index\n",
    "    if j > vocab_size:\n",
    "        print('{} has index {}, too large for vocab size {}').format(gw,j,vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22000, 22000)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_probs = np.full((vocab_size,vocab_size),-10.)\n",
    "cond_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(vocab_size):\n",
    "    for gw in gender_word_pairs_simple:\n",
    "        gw_i = wiki_model.wv.vocab[gw].index\n",
    "        v_prime_wo = wvs[i]\n",
    "        v_wi = cvs[gw_i]\n",
    "        samples = np.random.choice(vocab_size,size=k,replace=False,p=sampling_dist)\n",
    "        first_term = np.log(sigmoid((np.matmul(v_prime_wo,v_wi))))\n",
    "        second_term = np.sum([np.log(sigmoid(-1*np.matmul(wvs[s],v_wi))) for s in samples])\n",
    "        cond_probs[i,gw_i] = np.exp(first_term + second_term)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cond_probs = cond_probs / np.sum(cond_probs,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cond_probs_alt',cond_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "appropriately_gendered_words = [\"he\", \"his\", \"her\", \"she\", \"him\", \"man\", \"women\", \"men\", \"woman\", \"spokesman\", \"wife\", \"himself\", \"son\", \"mother\", \"father\", \"chairman\",\n",
    "\"daughter\", \"husband\", \"guy\", \"girls\", \"girl\", \"boy\", \"boys\", \"brother\", \"spokeswoman\", \"female\", \"sister\", \"male\", \"herself\", \"brothers\", \"dad\",\n",
    "\"actress\", \"mom\", \"sons\", \"girlfriend\", \"daughters\", \"lady\", \"boyfriend\", \"sisters\", \"mothers\", \"king\", \"businessman\", \"grandmother\",\n",
    "\"grandfather\", \"deer\", \"ladies\", \"uncle\", \"males\", \"congressman\", \"grandson\", \"bull\", \"queen\", \"businessmen\", \"wives\", \"widow\",\n",
    "\"nephew\", \"bride\", \"females\", \"aunt\", \"prostate cancer\", \"lesbian\", \"chairwoman\", \"fathers\", \"moms\", \"maiden\", \"granddaughter\",\n",
    "\"younger brother\", \"lads\", \"lion\", \"gentleman\", \"fraternity\", \"bachelor\", \"niece\", \"bulls\", \"husbands\", \"prince\", \"colt\", \"salesman\", \"hers\",\n",
    "\"dude\", \"beard\", \"filly\", \"princess\", \"lesbians\", \"councilman\", \"actresses\", \"gentlemen\", \"stepfather\", \"monks\", \"ex girlfriend\", \"lad\",\n",
    "\"sperm\", \"testosterone\", \"nephews\", \"maid\", \"daddy\", \"mare\", \"fiance\", \"fiancee\", \"kings\", \"dads\", \"waitress\", \"maternal\", \"heroine\",\n",
    "\"nieces\", \"girlfriends\", \"sir\", \"stud\", \"mistress\", \"lions\", \"estranged wife\", \"womb\", \"grandma\", \"maternity\", \"estrogen\", \"ex boyfriend\",\n",
    "\"widows\", \"gelding\", \"diva\", \"teenage girls\", \"nuns\", \"czar\", \"ovarian cancer\", \"countrymen\", \"teenage girl\", \"penis\", \"bloke\", \"nun\",\n",
    "\"brides\", \"housewife\", \"spokesmen\", \"suitors\", \"menopause\", \"monastery\", \"motherhood\", \"brethren\", \"stepmother\", \"prostate\",\n",
    "\"hostess\", \"twin brother\", \"schoolboy\", \"brotherhood\", \"fillies\", \"stepson\", \"congresswoman\", \"uncles\", \"witch\", \"monk\", \"viagra\",\n",
    "\"paternity\", \"suitor\", \"sorority\", \"macho\", \"businesswoman\", \"eldest son\", \"gal\", \"statesman\", \"schoolgirl\", \"fathered\", \"goddess\",\n",
    "\"hubby\", \"stepdaughter\", \"blokes\", \"dudes\", \"strongman\", \"uterus\", \"grandsons\", \"studs\", \"mama\", \"godfather\", \"hens\", \"hen\", \"mommy\",\n",
    "\"estranged husband\", \"elder brother\", \"boyhood\", \"baritone\", \"grandmothers\", \"grandpa\", \"boyfriends\", \"feminism\", \"countryman\",\n",
    "\"stallion\", \"heiress\", \"queens\", \"witches\", \"aunts\", \"semen\", \"fella\", \"granddaughters\", \"chap\", \"widower\", \"salesmen\", \"convent\",\n",
    "\"vagina\", \"beau\", \"beards\", \"handyman\", \"twin sister\", \"maids\", \"gals\", \"housewives\", \"horsemen\", \"obstetrics\", \"fatherhood\",\n",
    "\"councilwoman\", \"princes\", \"matriarch\", \"colts\", \"ma\", \"fraternities\", \"pa\", \"fellas\", \"councilmen\", \"dowry\", \"barbershop\", \"fraternal\",\n",
    "\"ballerina\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_in_matrix(words):\n",
    "    def get_index(w):\n",
    "        try: \n",
    "            return wiki_model.wv.vocab[w].index\n",
    "        except:\n",
    "            print(\"not in model: {}\".format(w))\n",
    "            return vocab_size+10\n",
    "    indices = list(map(lambda word: get_index(word), words))\n",
    "    indices = list(filter(lambda i: i < vocab_size, indices))\n",
    "    return np.flip(np.sort(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not in model: prostate cancer\n",
      "not in model: younger brother\n",
      "not in model: ex girlfriend\n",
      "not in model: estranged wife\n",
      "not in model: ex boyfriend\n",
      "not in model: teenage girls\n",
      "not in model: ovarian cancer\n",
      "not in model: teenage girl\n",
      "not in model: twin brother\n",
      "not in model: eldest son\n",
      "not in model: hubby\n",
      "not in model: estranged husband\n",
      "not in model: elder brother\n",
      "not in model: twin sister\n"
     ]
    }
   ],
   "source": [
    "app_gen_indices = get_indices_in_matrix(appropriately_gendered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 21997, 21998, 21999])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inapp_gen_indices = np.array(list((filter(lambda x: x not in app_gen_indices, np.arange(vocab_size)))))\n",
    "inapp_gen_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debias_vector_pairs(gender_pairs,model):\n",
    "    new_mat = cond_probs.copy()\n",
    "    for p1,p2 in gender_pairs:\n",
    "        print('debiasing distributions {} and {}'.format(p1,p2))\n",
    "        p1_index,p2_index = wiki_model.wv.vocab[p1].index,wiki_model.wv.vocab[p2].index\n",
    "        p1_dist = new_mat[inapp_gen_indices,p1_index]\n",
    "        p2_dist = new_mat[inapp_gen_indices,p2_index]\n",
    "#         print(p1_index)\n",
    "#         print(p2_index)\n",
    "        normed_p1_dist,normed_p2_dist = p1_dist/np.sum(p1_dist), p2_dist/np.sum(p2_dist)\n",
    "        A = np.vstack((normed_p1_dist, normed_p2_dist)).T\n",
    "        n_distributions = A.shape[1]\n",
    "        M = ot.utils.dist0(len(p1_dist))\n",
    "        M /= M.max()\n",
    "        alpha = 0.2  # 0<=alpha<=1\n",
    "        weights = np.array([1 - alpha, alpha])\n",
    "\n",
    "        # wasserstein\n",
    "        reg = 1e2\n",
    "        bary_wass = ot.bregman.barycenter(A, M, reg, weights)\n",
    "\n",
    "        new_mat[inapp_gen_indices,p1_index] = bary_wass * np.sum(p1_dist)\n",
    "        new_mat[inapp_gen_indices,p2_index] = bary_wass * np.sum(p2_dist)\n",
    "    return new_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: `debias_vector_pairs` takes ~1 hour for `vocab_size` 22000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debiasing distributions he and she\n",
      "debiasing distributions man and woman\n",
      "debiasing distributions his and her\n",
      "debiasing distributions himself and herself\n",
      "debiasing distributions him and her\n",
      "debiasing distributions men and women\n",
      "debiasing distributions husband and wife\n",
      "debiasing distributions girl and boy\n",
      "debiasing distributions men and women\n",
      "debiasing distributions brother and sister\n",
      "debiasing distributions mother and father\n",
      "debiasing distributions aunt and uncle\n",
      "debiasing distributions grandfather and grandmother\n",
      "debiasing distributions son and daughter\n",
      "debiasing distributions waiter and waitress\n",
      "debiasing distributions niece and nephew\n"
     ]
    }
   ],
   "source": [
    "new_mat = debias_vector_pairs(gender_word_pairs,wiki_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('debiased_matrix_alt',new_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debiased_matrix_alt = np.load('debiased_matrix_alt.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mat.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gw in gender_word_pairs_simple:\n",
    "    j = wiki_model.wv.vocab[gw].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "debiased_matrix_alt_orig = np.load('debiased_matrix_alt_orig.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he',\n",
       " 'she',\n",
       " 'man',\n",
       " 'woman',\n",
       " 'his',\n",
       " 'her',\n",
       " 'himself',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'her',\n",
       " 'men',\n",
       " 'women',\n",
       " 'husband',\n",
       " 'wife',\n",
       " 'girl',\n",
       " 'boy',\n",
       " 'men',\n",
       " 'women',\n",
       " 'brother',\n",
       " 'sister',\n",
       " 'mother',\n",
       " 'father',\n",
       " 'aunt',\n",
       " 'uncle',\n",
       " 'grandfather',\n",
       " 'grandmother',\n",
       " 'son',\n",
       " 'daughter']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_word_pairs_simple[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_inds = np.array([wiki_model.wv.vocab[w].index for w in gender_word_pairs_simple[:-4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "debiased_matrix_alt_new = debiased_matrix_alt_orig[:,gender_inds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00145599, 0.0009459 , 0.00078978, ..., 0.00764814, 0.00196016,\n",
       "        0.00335457],\n",
       "       [0.00145599, 0.0009459 , 0.00078978, ..., 0.00764814, 0.00196016,\n",
       "        0.00335458],\n",
       "       [0.00145599, 0.0009459 , 0.00078978, ..., 0.00764814, 0.00196016,\n",
       "        0.00335458],\n",
       "       ...,\n",
       "       [0.00145503, 0.00094527, 0.00078967, ..., 0.0076529 , 0.0019618 ,\n",
       "        0.00335737],\n",
       "       [0.00145503, 0.00094527, 0.00078967, ..., 0.00765289, 0.00196179,\n",
       "        0.00335737],\n",
       "       [0.00145503, 0.00094527, 0.00078967, ..., 0.00765289, 0.00196179,\n",
       "        0.00335737]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_matrix_alt_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22000, 28)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_matrix_alt_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.20817376e+01,  2.12393562e+01,  1.73919306e+01,  4.53784911e+01,\n",
       "        1.41643720e+01,  1.37905362e+01,  2.62910136e+01,  6.39612812e+01,\n",
       "       -2.20000000e+04,  1.37905362e+01,  1.26560006e+01,  2.05652309e+01,\n",
       "        1.77254850e+02,  7.65797569e+01,  4.50427632e+01,  3.43724390e+01,\n",
       "        1.26560006e+01,  2.05652309e+01,  6.33170209e+01,  9.00972107e+01,\n",
       "        6.06649260e+01,  3.64134071e+01,  1.76325032e+02,  1.10796437e+02,\n",
       "        1.27379415e+02,  1.71522826e+02,  4.36932426e+01,  7.55931071e+01])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_matrix_alt_new.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('debiased_matrix_alt_orig_reshaped',debiased_matrix_alt_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
