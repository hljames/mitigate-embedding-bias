{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Dense, Input, Reshape, Flatten\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debiased_probs = np.load('debiased_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(debiased_probs)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.arange(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 21997, 21998, 21999])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = debiased_probs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "input_word = Input((1,))\n",
    "embedding = Embedding(vocab_size, vector_dim, input_length=1, name='embedding')(input_word)\n",
    "flatten = Flatten()(embedding)\n",
    "output = Dense(vocab_size, activation='softmax')(flatten)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haileyjames/anaconda2/envs/p3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model = Model(input=input_word, output=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='kld', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 1, 100)            2200000   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 22000)             2222000   \n",
      "=================================================================\n",
      "Total params: 4,422,000\n",
      "Trainable params: 4,422,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22000/22000 [==============================] - 176s 8ms/step - loss: 0.8577 - acc: 0.8513\n",
      "Epoch 2/50\n",
      "22000/22000 [==============================] - 73s 3ms/step - loss: 0.8253 - acc: 0.8561\n",
      "Epoch 3/50\n",
      "22000/22000 [==============================] - 70s 3ms/step - loss: 0.7952 - acc: 0.8580\n",
      "Epoch 4/50\n",
      "22000/22000 [==============================] - 69s 3ms/step - loss: 0.7677 - acc: 0.8620\n",
      "Epoch 5/50\n",
      "22000/22000 [==============================] - 70s 3ms/step - loss: 0.7412 - acc: 0.8658\n",
      "Epoch 6/50\n",
      "22000/22000 [==============================] - 71s 3ms/step - loss: 0.7172 - acc: 0.8690\n",
      "Epoch 7/50\n",
      "22000/22000 [==============================] - 68s 3ms/step - loss: 0.6941 - acc: 0.8713\n",
      "Epoch 8/50\n",
      "22000/22000 [==============================] - 73s 3ms/step - loss: 0.6729 - acc: 0.8748\n",
      "Epoch 9/50\n",
      "22000/22000 [==============================] - 71s 3ms/step - loss: 0.6531 - acc: 0.8772\n",
      "Epoch 10/50\n",
      "22000/22000 [==============================] - 69s 3ms/step - loss: 0.6352 - acc: 0.8805\n",
      "Epoch 11/50\n",
      "22000/22000 [==============================] - 68s 3ms/step - loss: 0.6180 - acc: 0.8820\n",
      "Epoch 12/50\n",
      "22000/22000 [==============================] - 68s 3ms/step - loss: 0.6018 - acc: 0.8840\n",
      "Epoch 13/50\n",
      "22000/22000 [==============================] - 79s 4ms/step - loss: 0.5862 - acc: 0.8862\n",
      "Epoch 14/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.5726 - acc: 0.8887\n",
      "Epoch 15/50\n",
      "22000/22000 [==============================] - 66s 3ms/step - loss: 0.5600 - acc: 0.8910\n",
      "Epoch 16/50\n",
      "22000/22000 [==============================] - 68s 3ms/step - loss: 0.5474 - acc: 0.8928\n",
      "Epoch 17/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.5358 - acc: 0.8937\n",
      "Epoch 18/50\n",
      "22000/22000 [==============================] - 70s 3ms/step - loss: 0.5248 - acc: 0.8958\n",
      "Epoch 19/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.5145 - acc: 0.8977\n",
      "Epoch 20/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.5056 - acc: 0.8994\n",
      "Epoch 21/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.4966 - acc: 0.9012\n",
      "Epoch 22/50\n",
      "22000/22000 [==============================] - 68s 3ms/step - loss: 0.4889 - acc: 0.9020\n",
      "Epoch 23/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.4808 - acc: 0.9042\n",
      "Epoch 24/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.4740 - acc: 0.9056\n",
      "Epoch 25/50\n",
      "22000/22000 [==============================] - 68s 3ms/step - loss: 0.4669 - acc: 0.9058\n",
      "Epoch 26/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.4611 - acc: 0.9060\n",
      "Epoch 27/50\n",
      "22000/22000 [==============================] - 68s 3ms/step - loss: 0.4551 - acc: 0.9075\n",
      "Epoch 28/50\n",
      "22000/22000 [==============================] - 68s 3ms/step - loss: 0.4493 - acc: 0.9082\n",
      "Epoch 29/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.4446 - acc: 0.9090\n",
      "Epoch 30/50\n",
      "22000/22000 [==============================] - 68s 3ms/step - loss: 0.4403 - acc: 0.9094\n",
      "Epoch 31/50\n",
      "22000/22000 [==============================] - 68s 3ms/step - loss: 0.4359 - acc: 0.9097\n",
      "Epoch 32/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.4316 - acc: 0.9117\n",
      "Epoch 33/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.4280 - acc: 0.9127\n",
      "Epoch 34/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.4250 - acc: 0.9147\n",
      "Epoch 35/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.4223 - acc: 0.9120: 2s - loss\n",
      "Epoch 36/50\n",
      "22000/22000 [==============================] - 68s 3ms/step - loss: 0.4193 - acc: 0.9140\n",
      "Epoch 37/50\n",
      "22000/22000 [==============================] - 69s 3ms/step - loss: 0.4170 - acc: 0.9137\n",
      "Epoch 38/50\n",
      "22000/22000 [==============================] - 68s 3ms/step - loss: 0.4150 - acc: 0.9154\n",
      "Epoch 39/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.4126 - acc: 0.9143\n",
      "Epoch 40/50\n",
      "22000/22000 [==============================] - 70s 3ms/step - loss: 0.4109 - acc: 0.9148\n",
      "Epoch 41/50\n",
      "22000/22000 [==============================] - 75s 3ms/step - loss: 0.4096 - acc: 0.9159\n",
      "Epoch 42/50\n",
      "22000/22000 [==============================] - 70s 3ms/step - loss: 0.4086 - acc: 0.9136\n",
      "Epoch 43/50\n",
      "22000/22000 [==============================] - 69s 3ms/step - loss: 0.4075 - acc: 0.9149\n",
      "Epoch 44/50\n",
      "22000/22000 [==============================] - 68s 3ms/step - loss: 0.4065 - acc: 0.9159\n",
      "Epoch 45/50\n",
      "22000/22000 [==============================] - 68s 3ms/step - loss: 0.4065 - acc: 0.9164\n",
      "Epoch 46/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.4061 - acc: 0.9152\n",
      "Epoch 47/50\n",
      "22000/22000 [==============================] - 68s 3ms/step - loss: 0.4061 - acc: 0.9157\n",
      "Epoch 48/50\n",
      "22000/22000 [==============================] - 69s 3ms/step - loss: 0.4062 - acc: 0.9164\n",
      "Epoch 49/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.4064 - acc: 0.9149\n",
      "Epoch 50/50\n",
      "22000/22000 [==============================] - 67s 3ms/step - loss: 0.4068 - acc: 0.9152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xc23507f98>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_100_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_100_epochs_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array(model.get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999896"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_model = Word2Vec.load(\"english-wikipedia-articles-20170820-models/enwiki_2017_08_20_fasttext.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('debiased_embedding.txt', 'w') as we:\n",
    "    we.write('{} {}\\n'.format(vocab_size,vector_dim))\n",
    "    for i in range(vocab_size):\n",
    "        w = wiki_model.wv.index2word[i]\n",
    "        vec = weights[i]\n",
    "        we.write('{} '.format(w))\n",
    "        for v in vec:\n",
    "            we.write(str(v) + ' ')\n",
    "        we.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_debiased = KeyedVectors.load_word2vec_format('debiased_embedding.txt', binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haileyjames/anaconda2/envs/p3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model_debiased.wv.save_word2vec_format('debiased_model_100.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_model.wv.save_word2vec_format('biased_model_full.txt', binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22001 debiased_embedding.txt\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l 'debiased_embedding.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 22001 'biased_model_full.txt' > 'biased_model.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_biased = KeyedVectors.load_word2vec_format('biased_model.txt', binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haileyjames/anaconda2/envs/p3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model_biased.wv.save_word2vec_format('fast_text_small.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7756180763244629),\n",
       " ('monarch', 0.7246657609939575),\n",
       " ('princess', 0.7197414040565491),\n",
       " ('prince', 0.7065383195877075),\n",
       " ('empress', 0.6887034177780151),\n",
       " ('regent', 0.6676155924797058),\n",
       " ('consort', 0.6602832078933716),\n",
       " ('marriage', 0.6249816417694092),\n",
       " ('constantine', 0.6138389110565186),\n",
       " ('emperor', 0.6067585945129395)]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_biased.most_similar(positive=['woman', 'king'], negative=['man'])               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('isabella', 0.7068111300468445),\n",
       " ('deposed', 0.6896980404853821),\n",
       " ('constantine', 0.687233567237854),\n",
       " ('sigismund', 0.6663229465484619),\n",
       " ('prince', 0.6559014320373535),\n",
       " ('regent', 0.654486894607544),\n",
       " ('crowned', 0.6519841551780701),\n",
       " ('philip', 0.6483753323554993),\n",
       " ('iii', 0.6431190371513367),\n",
       " ('ferdinand', 0.6400526762008667)]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_debiased.most_similar(positive=['woman', 'king'], negative=['man'])               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mosul', 0.7500249147415161),\n",
       " ('syria', 0.7329857349395752),\n",
       " ('iraq', 0.7099663019180298),\n",
       " ('yemen', 0.703923761844635),\n",
       " ('libya', 0.6781851649284363),\n",
       " ('afghanistan', 0.6734411716461182),\n",
       " ('iraqi', 0.6579854488372803),\n",
       " ('aleppo', 0.654990017414093),\n",
       " ('tripoli', 0.6461622714996338),\n",
       " ('damascus', 0.64577716588974)]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_biased.most_similar(positive=['baghdad', 'england'], negative=['london'])               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('syrian', 0.6814754009246826),\n",
       " ('governorate', 0.6789872646331787),\n",
       " ('arab', 0.6772698163986206),\n",
       " ('mahmoud', 0.6739144921302795),\n",
       " ('jordanian', 0.6720398664474487),\n",
       " ('masjid', 0.6697014570236206),\n",
       " ('sunni', 0.6684684753417969),\n",
       " ('wal', 0.6664949655532837),\n",
       " ('amr', 0.6647167205810547),\n",
       " ('amin', 0.6625057458877563)]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_debiased.most_similar(positive=['baghdad', 'england'], negative=['london'])               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('psychiatrist', 0.6780833601951599),\n",
       " ('nurse', 0.6779659986495972),\n",
       " ('dentist', 0.6075595617294312),\n",
       " ('teacher', 0.6025106906890869),\n",
       " ('psychologist', 0.5949655771255493),\n",
       " ('mistress', 0.5942846536636353),\n",
       " ('physician', 0.5904124975204468),\n",
       " ('counselor', 0.5747247338294983),\n",
       " ('tutor', 0.5684062838554382),\n",
       " ('professor', 0.5608705282211304)]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_biased.most_similar(positive=['woman', 'doctor'], negative=['man'])               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scientist', 0.6410385370254517),\n",
       " ('psychiatrist', 0.6191622614860535),\n",
       " ('dr', 0.6027106046676636),\n",
       " ('dean', 0.5591259598731995),\n",
       " ('physician', 0.5469638109207153),\n",
       " ('prof', 0.5324706435203552),\n",
       " ('professor', 0.5117653608322144),\n",
       " ('researcher', 0.5073388814926147),\n",
       " ('psychologist', 0.5047338604927063),\n",
       " ('loren', 0.5018652081489563)]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_debiased.most_similar(positive=['woman', 'doctor'], negative=['man'])               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
