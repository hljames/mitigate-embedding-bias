{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Dense, Input, Reshape, Flatten, dot\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import itertools\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "debiased_probs = np.load('debiased_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(debiased_probs)\n",
    "# vocab_size = 22000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not input_size or vocab_size % input_size:\n",
    "    print('ERROR: input size must be divisible by vocab size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.arange(vocab_size)\n",
    "x_train = np.array([xs[i * input_size:(i + 1) * input_size] for i in range((len(xs) + input_size - 1) // input_size )])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 22)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([debiased_probs[x[0]:x[-1]+1,x[0]:x[-1]+1] for x in x_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 22, 22)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_model = Word2Vec.load(\"english-wikipedia-articles-20170820-models/enwiki_2017_08_20_fasttext.model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. change this so it takes in a batch (either by passing in batches or changing the dimension of the input)\n",
    "\n",
    "2. Have the output be the dot product of the embeddings of the batch (EX: if the list of words is x, and the embedding of each of the words is X, then the output is C = X dot X)\n",
    "\n",
    "3. Have the loss function accumulate the loss for each value normalized with negative sampling (double four loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "input_i = Input((input_size,))\n",
    "embedding = Embedding(vocab_size, vector_dim, input_length=input_size, name='embedding')\n",
    "vec_i = embedding(input_i)\n",
    "vec_i = Reshape((vector_dim, input_size))(vec_i)\n",
    "dot_product = dot([vec_i, vec_i], axes=1)\n",
    "# dot_product = Reshape((1,))(dot_product)\n",
    "output = Dense(1, activation='linear')(dot_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haileyjames/anaconda2/envs/p3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model = Model(input=[input_i], output=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_pred,y_true):\n",
    "    loss = 0\n",
    "    indices = np.arange(input_size)\n",
    "    for i in indices:\n",
    "        for j in indices:\n",
    "            indices_tensor = tf.convert_to_tensor([[0,m,j] for m in np.where(indices!=i)[0]])\n",
    "#             print(tf.shape(indices_tensor))\n",
    "#             print(tf.shape(y_pred))\n",
    "#             print(sess.run(indices_tensor[0]))\n",
    "            neg_samples = K.sigmoid(-1*tf.gather_nd(y_pred,indices_tensor))\n",
    "            neg_sample_sum = K.sum(K.log(neg_samples))\n",
    "            curr_ind = tf.convert_to_tensor([[0,i,j]])\n",
    "            pred = K.log(K.sigmoid(tf.gather_nd(y_pred,curr_ind))) + neg_sample_sum\n",
    "            loss += (K.log(y_true) - pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss=custom_loss, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 22)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 22, 100)      2200000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 100, 22)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 22, 22)       0           reshape_1[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 22, 1)        23          dot_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 2,200,023\n",
      "Trainable params: 2,200,023\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_weights = wiki_model.wv.vectors[:vocab_size,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "layer_dict['embedding'].set_weights([original_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('untrained_reconstruction_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('untrained_reconstruction_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: nan - acc: 4.1322e-06\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 1.0331e-05\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 1.8595e-05\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 8.2645e-06\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 2.0661e-05\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 3.3058e-05\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 2.8926e-05\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 1.6529e-05\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 2.4793e-05\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 3.3058e-05\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 2.2727e-05\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 3.0992e-05\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 3.5124e-05\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 2.8926e-05\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 3.0992e-05\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 3.5124e-05\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 3.5124e-05\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 5.1653e-05\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 5.9917e-05\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 3.7190e-05\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 3.5124e-05\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 5.9917e-05\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 4.7521e-05\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 5.7851e-05\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 4.1322e-05\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 5.7851e-05\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 6.1983e-05\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 6.1983e-05\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 4.5455e-05\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 7.2314e-05\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 4.9587e-05\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 3.9256e-05\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 7.6446e-05\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 4.1322e-05\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 5.3719e-05\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 7.6446e-05\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 5.9917e-05\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 7.0248e-05\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 5.7851e-05\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 6.8182e-05\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 6.1983e-05\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 5.5785e-05\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 7.8512e-05\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 7.0248e-05\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 7.4380e-05\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 7.4380e-05\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 6.6116e-05\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 5.3719e-05\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 5.7851e-05\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: nan - acc: 6.6116e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b4f0e3f28>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trained_reconstruction_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('trained_reconstruction_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array(model.get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('debiased_embedding.txt', 'w') as we:\n",
    "    we.write('{} {}\\n'.format(vocab_size,vector_dim))\n",
    "    for i in range(vocab_size):\n",
    "        w = wiki_model.wv.index2word[i]\n",
    "        vec = weights[i]\n",
    "        we.write('{} '.format(w))\n",
    "        for v in vec:\n",
    "            we.write(str(v) + ' ')\n",
    "        we.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_debiased = KeyedVectors.load_word2vec_format('debiased_embedding.txt', binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haileyjames/anaconda2/envs/p3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "# model_debiased.wv.save_word2vec_format('debiased_model_100.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_model.wv.save_word2vec_format('biased_model_full.txt', binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !head -n 22001 'biased_model_full.txt' > 'biased_model.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_biased = KeyedVectors.load_word2vec_format('biased_model.txt', binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haileyjames/anaconda2/envs/p3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "# model_biased.wv.save_word2vec_format('fast_text_small.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7756180763244629),\n",
       " ('monarch', 0.7246657609939575),\n",
       " ('princess', 0.7197414040565491),\n",
       " ('prince', 0.7065383195877075),\n",
       " ('empress', 0.6887034177780151),\n",
       " ('regent', 0.6676155924797058),\n",
       " ('consort', 0.6602832078933716),\n",
       " ('marriage', 0.6249816417694092),\n",
       " ('constantine', 0.6138389110565186),\n",
       " ('emperor', 0.6067585945129395)]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_biased.most_similar(positive=['woman', 'king'], negative=['man'])               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7746890187263489),\n",
       " ('monarch', 0.7205826640129089),\n",
       " ('princess', 0.7195833325386047),\n",
       " ('prince', 0.7071539759635925),\n",
       " ('empress', 0.6903455257415771),\n",
       " ('regent', 0.6701014041900635),\n",
       " ('consort', 0.6536059975624084),\n",
       " ('marriage', 0.6225910186767578),\n",
       " ('constantine', 0.6129751801490784),\n",
       " ('emperor', 0.6064161658287048)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_debiased.most_similar(positive=['woman', 'king'], negative=['man'])               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mosul', 0.7500249147415161),\n",
       " ('syria', 0.7329857349395752),\n",
       " ('iraq', 0.7099663019180298),\n",
       " ('yemen', 0.703923761844635),\n",
       " ('libya', 0.6781851649284363),\n",
       " ('afghanistan', 0.6734411716461182),\n",
       " ('iraqi', 0.6579854488372803),\n",
       " ('aleppo', 0.654990017414093),\n",
       " ('tripoli', 0.6461622714996338),\n",
       " ('damascus', 0.64577716588974)]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_biased.most_similar(positive=['baghdad', 'england'], negative=['london'])               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mosul', 0.7513368129730225),\n",
       " ('syria', 0.7309308052062988),\n",
       " ('iraq', 0.7116736173629761),\n",
       " ('yemen', 0.7084739208221436),\n",
       " ('libya', 0.676697850227356),\n",
       " ('afghanistan', 0.6735158562660217),\n",
       " ('iraqi', 0.6566969156265259),\n",
       " ('aleppo', 0.651322066783905),\n",
       " ('tripoli', 0.6423690915107727),\n",
       " ('damascus', 0.6417893171310425)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_debiased.most_similar(positive=['baghdad', 'england'], negative=['london'])               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('psychiatrist', 0.6780833601951599),\n",
       " ('nurse', 0.6779659986495972),\n",
       " ('dentist', 0.6075595617294312),\n",
       " ('teacher', 0.6025106906890869),\n",
       " ('psychologist', 0.5949655771255493),\n",
       " ('mistress', 0.5942846536636353),\n",
       " ('physician', 0.5904124975204468),\n",
       " ('counselor', 0.5747247338294983),\n",
       " ('tutor', 0.5684062838554382),\n",
       " ('professor', 0.5608705282211304)]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_biased.most_similar(positive=['woman', 'doctor'], negative=['man'])               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('psychiatrist', 0.6768365502357483),\n",
       " ('nurse', 0.6762781143188477),\n",
       " ('dentist', 0.601752758026123),\n",
       " ('teacher', 0.6015279293060303),\n",
       " ('psychologist', 0.5945874452590942),\n",
       " ('mistress', 0.5942332148551941),\n",
       " ('physician', 0.5875041484832764),\n",
       " ('counselor', 0.5739505290985107),\n",
       " ('tutor', 0.5650268793106079),\n",
       " ('professor', 0.5599614381790161)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_debiased.most_similar(positive=['woman', 'doctor'], negative=['man'])               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
